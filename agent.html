<!DOCTYPE html>
<html>
<head>
<meta charset='utf-8'>
<title>Multi-agent systems</title>
    
<link href="css/site.css" media="screen" rel="stylesheet" type="text/css" />
<link href="css/highlight.default.css" media="screen" rel="stylesheet" type="text/css" />
  
<script src="js/jquery.js"></script>
<script src="js/socket.io.js"></script>
<script src="js/main.js" type="text/javascript"></script>

<link rel="icon" type="image/x-icon" href="favicon.ico" />
</head>
<body>
<div id="wrapper">
	
	<div class="header">
		<h1>GCT 753</h1>
		<a href="index.html">Overview</a><br/>
		<a href="software.html">Software</a><br/>
		<a href="lua.html">Lua Tutorial</a><br/>
		&gt;&gt; <a href="https://github.com/grrrwaaa/gct753">GitHub</a><br/>
		&gt;&gt; <a href="http://grrrwaaa.github.com/gct753/docs/reference.html">Reference</a><br/>
		<br>
		<a href="introduction.html">Themes</a><br/>
		<a href="artificial_life.html">Artificial Life</a><br/>
		<a href="generative_art.html">Generative Art</a><br/>
		<a href="cellular.html">Cellular Systems</a><br/>
		<a href="agent.html">Agent Systems</a><br/>
		<a href="symbol.html">Symbol Systems</a><br/>
		<a href="evolutionary.html">Evolutionary Systems</a><br/>
		
	</div>
	<div class="section"><h1>Multi-agent systems (agent-based models)</h1>
<h2>What is an agent?</h2>
<p>An autonomous agent interacts within an environment populated by other agents, but behaves independently without taking direct commands from other agents nor a global planner or leader. Agent-based models typically operate in parallel within a spatial environment, in which interactions are usually limited to local distances, rather like cellular automata. But unlike CA, which roots a program in a particular spatial location (the cell), an agent-based program is typically mobile. </p>
<p>The agent abstraction has arisen somewhat independently in different fields, thus the definition of an agent can vary widely. The following components are usually present:</p>
<ul>
<li><strong>Properties</strong>: Persistent but variable features of an agent, such as size, color, speed, direction, energy level, and so on. </li>
<li><strong>Input</strong>: Limited capabilities of sensing (or receiving messages from) the environment</li>
<li><strong>Output</strong>: Limited capabilities of performing actions on (or sending messages to) the environment, or its own properties. Typically this includes the ability to move through space.</li>
<li><strong>Processing</strong>: An information processing capacity to select actions in response to inputs. This capacity may also include information storage (memory).</li>
<li><strong>Motivations</strong>: The agent may also incorporate explicit goals or purposes in the form of self-evaluation and self-adaptation; or these may be implict in the design of the processing algorithm.</li>
</ul>
<p>As a biological approximation, an agent could refer to anything from individual proteins, viruses, cells, bacteria, organisms, or population groups. Agent systems also share similarities with particle systems.</p>
<p>Just like CA, at times, the self-organizing behavior of systems of even relatively simple agents can be unpredictable, complex, and generate new emergent structures of order. </p>
<h2>Vehicles</h2>
<p>Braitenberg, V. (1984). Vehicles: Experiments in synthetic psychology. Cambridge, MA: MIT Press. </p>
<p><img src="http://www.ini.uzh.ch/~conradt/research/BraitenbergVehicle/Braitenberg%20Vehikels_files/BVinh.jpg" alt="Vehicle"></p>
<blockquote>
<p>A Braitenberg vehicle is an agent that can autonomously move around. It has primitive sensors (measuring some stimulus at a point) and wheels (each driven by its own motor) that function as actuators or effectors. A sensor, in the simplest configuration, is directly connected to an effector, so that a sensed signal immediately produces a movement of the wheel. Depending on how sensors and wheels are connected, the vehicle exhibits different behaviors (which can be goal-oriented).  <a href="http://en.wikipedia.org/wiki/Braitenberg_vehicle">wikipedia</a></p>
</blockquote>
<p>Cyberneticist Valentino Braitenberg argues that his extraordinarily simple mechanical vehicles manifest behaviors that appear identifiable as fear, aggression, love, foresight, and optimism. The vehicle idea was a thought experiment conceived to show that complex, apparently purposive behaviour did not need to depend on complex representations of the environment inside a creature or agents brain. In fact simply by reacting to the environment in a consistent manner was more than enough to explain the low level reactive behaviours exhibited by many animals.</p>
<p>Casey Reas (co-author of Processing), Yanni Loukissas, and many others have used populations of Braitenberg-inspired vehicles to create artworks based on their combined paths.</p>
<p><img src="http://reas.com/tissue_p/reas_tissue_p_13.jpg" alt="Reas&#39; Tissue"></p>
<p>Vehicles have also been constructed in hardware of course -- see examples <a href="http://www.ini.uzh.ch/~conradt/research/BraitenbergVehicle/">here</a>, <a href="http://blog.electricbricks.com/en/2010/05/vehiculos-braitenberg-nxt-g/">here</a>, <a href="http://tinkerlog.com/2009/06/07/mini-braitenberg-vehicle/">here</a> -- and may even have been inspired by <a href="http://en.wikipedia.org/wiki/William_Grey_Walter">Grey Walter</a>&#39;s robotic tortoises from the 1950s. (Brief history <a href="http://www.rutherfordjournal.org/article020101.html">here</a>).</p>
<p><img src="img/machina_speculatrix.jpg" alt="Machina Speculatrix"> </p>
<h3>Steering Behaviors</h3>
<p>Craig Reynolds&#39; work with robotics is strongly inspired by Braitenberg&#39;s and Walter&#39;s vehicles, and became famous for his work on simulating flocking behavior (see below). His work has been widely used in robotics, game design, special effects and simulation. Reynolds&#39; paper <a href="http://www.red3d.com/cwr/steer/gdc99/">Steering Behaviors for Autonomous Characters</a> breaks agent movement into three layers:</p>
<ul>
<li><strong>Action Selection</strong>: selecting actions to perform according to environmental input and goals to achieve. </li>
<li><strong>Steering</strong>: path determination according to the action selected. Many different behaviors can be used; a simple particle-system model could be <code>steering force = desired_velocity - current_velocity</code>.</li>
<li><strong>Locomotion</strong>: mechanisms of conversion of steering into actual movement.</li>
</ul>
<p>The paper is well worth exploring as a collection of patterns for autonomous agent movements; and presents the elements that make up his simulation of flocking behavior.</p>
<h3>Random walks in nature</h3>
<p>A <strong>random walk</strong> involves small random deviations to steering. This produces a <strong>random walk</strong> or <strong>Brownian motion</strong>, a form of movement that is widely utilized by nature. In Reynolds&#39; paper it is the <em>wander</em> steering strategy.</p>
<h3>Boids, flocking, swarms</h3>
<p>In the late 1980s Reynolds proposed a model of animal motion to model flocks, herds and schools, which he named <em>boids</em>. Each boid follows a set of rules based on simple principles:</p>
<ul>
<li><strong>Avoidance</strong>: Move away from other boids that are too close (avoid collision)</li>
<li><strong>Copy</strong>: Fly in the same general direction as other nearby boids</li>
<li><strong>Center</strong>: Move toward the center of the flock (avoid exposure)</li>
</ul>
<p>(Gary Flake also recommends adding an influence for <em>View</em>: to move laterally away from any boid blocking the view.)</p>
<p>To make this more realistic, we can consider that each boid can only perceive other boids within a certain distance and viewing angle. We should also restrict how quickly boids can change direction and speed (to account for momentum). Additionally, the avoidance rule may carry greater <em>weight</em> or take precedence over the other rules.</p>
<p>Evidently the <em>properties</em> of a boid (apart from location) include direction and speed. It could be assumed that viewing angle and range are shared by all boids, or these could also vary per individual. The <em>sensors</em> of a boid include an ability to detect the density of boids in different directions (to detect the center of the flock), as well as the average speed and direction of boids, within a viewable area. The <em>actions</em> of a boid principally are to alter the direction and speed of flight. </p>
<hr>
<h2>Environmental interaction</h2>
<h3>Termites</h3>
<p>Mitchel Resnick&#39;s termite model is a random walker in a space that can contain woodchips, in which each termite can carry one woodchip at a time. The program for a termite looks something like this:</p>
<ul>
<li>Look at the space just in front of me</li>
<li>If it is empty, move forward and randomly change direction (random walk)</li>
<li>Else if it is occupied by a woodchip:<ul>
<li>If I am carrying a wood chip, drop mine where I am and turn around</li>
<li>Else move forward and pick up the woodchip</li>
</ul>
</li>
</ul>
<p>Over time, the termites begin to collect the woodchips into small piles, which gradually coalesce into a single large pile of chips.</p>
<h3>Chemotaxis</h3>
<blockquote>
<p>Chemotaxis is the phenomenon whereby somatic cells, bacteria, and other single-cell or multicellular organisms direct their movements according to certain chemicals in their environment. This is important for bacteria to find food (for example, glucose) by swimming towards the highest concentration of food molecules, or to flee from poisons (for example, phenol). In multicellular organisms, chemotaxis is critical to early development (e.g. movement of sperm towards the egg during fertilization) and subsequent phases of development (e.g. migration of neurons or lymphocytes) as well as in normal function. <a href="https://en.wikipedia.org/wiki/Chemotaxis">wikipedia</a></p>
</blockquote>
<p>A <a href="http://www.youtube.com/watch?v=ZV5CfOkV6ek">video example of chemotaxis in E. coli</a>.</p>
<p>E. coli can use its flagella to move in just two modes (<em>locomotion</em>): </p>
<ul>
<li>Move forward more or less straight</li>
<li>Tumble about randomly</li>
</ul>
<p>The <em>goal</em> is to find the highest sugar concentration. It can sense the local sugar concentration at its current location. However it cannot sense at a distance, and has no sense of direction, never mind which direction is best. </p>
<p>Instead it uses chemical memory to detect sugar concentration <em>gradient</em>, that is, the differential of concentration at the current location compared to how it was just a few moments ago. This gradient tells the E. coli whether things are getting better or worse, which can be used to select between the swimming or tumbling patterns. </p>
<p>With just a few tuning parameters, this can lead to a very rapid success in finding the higher concentrations of sugar (assuming the environment is smoothly varying). </p>
<p>A variety of other <em>taxes</em> worth exploring can be found on the <a href="http://en.wikipedia.org/wiki/Taxis#Aerotaxis">wikipedia page</a>. Note how chemotaxis (and other taxes) can be divided into positive (attractive) and negative (repulsive) characters, just like forces (directly seen in steering forces). This is closely related to the concepts of positive and negative feedback. </p>
<h3>Stigmergy</h3>
<p><em>Stigmergy</em> is a mechanism of indirect coordination between agents by leaving traces in the environment as a mode of stimulating future action by agents in the same location. For example, ants (and some other social insects) lay down a trace of pheromones when returning to the nest while carrying food. Future ants are attracted to follow these trails, increasing the likelihood of encountering food. This environmental marking constitutes a shared external memory (without needing a map). However if the food source is exhausted, the pheromone trails will gradually fade away, leading to new foraging behavior. </p>
<p>Traces evidently lead to self-reinforcement and self-organization: complex and seeminly intelligent structures without global planning or control. Since the term stigmergy focuses on self-reinforcing, task-oriented signaling, E. O. Wilson suggested a more general term <em>sematectonic communication</em> for environmental communication that is not necessarily task-oriented.</p>
<p>Stigmergy has become a key concept in the field of <a href="http://en.wikipedia.org/wiki/Swarm_intelligence">swarm intelligence</a>, and the method of <em>ant colony optimization</em> in particular. In ACO, the landscape is a parameter space (possibly much larger than two or three dimensions) in which populations of virtual agents leave pheromone trails to high-scoring solutions.</p>
<p>Related environmental communication strategies include social nest construction (e.g. termites) and territory marking.</p>
<h2>Action selection systems</h2>
<h3>Subsumption architecture</h3>
<p>Rodney Brooks was also strongly influenced by Braitenberg&#39;s vehicles.</p>
<h3>Neural networks</h3>
<p>The neuron, von Neumann, biological &amp; artificial plasticity, artificial neural networks (ANNs), supervised, unsupervised &amp; reinforcement learning.</p>
<h3>Complex adaptive systems</h3>
<h1>Assignment 2: Agent Systems</h1>
<p>The second assignment is to construct a new agent-based system. You can start from one of the existing systems we have looked at and modify it, or design and create a new one to explore an idea you have. The agents should implement local interactions using one or both of:</p>
<ul>
<li>Sensing and responding to other nearby (locally visible) agents</li>
<li>Local reading and/or writing to one or more fields</li>
</ul>
<p>Your agents should also implement:</p>
<ul>
<li>Action selection (responding to context in order to choose between strategies)</li>
<li>Steering (implementing strategies by deriving and applying forces)</li>
<li>Locomotion (implementing these forces to move the agents)</li>
</ul>
<p>You should also try adding at least one of the following:</p>
<ul>
<li>More than one type of agent (e.g. predator and prey)</li>
<li>Birth and death</li>
<li>Field dynamics (a field that changes over time)</li>
<li>Keyboard and mouse interaction</li>
</ul>
<p>You might spend roughly a third of your time choosing what to try and designing, a third actually implementing it, and a third exploring it for interesting parameters, initial conditions, variations etc. If you end up with more than one system that is interesting, you can submit them all. If you had an idea that seemed interesting but was difficult to implement or did not lead to interesting results, submit that too (with an explanation of why you think it did not work or did not do what you expected); this is just as important a part of research.</p>
<p>Document your work using comments in the code. Note that in Lua, you can write long multi-line comments like this:</p>
<pre><code class="lang-lua"><span class="comment">--[[
This is a long comment
that runs over
several lines
--]]</span></code></pre>
<p>At the top of your code, there should be a long comment including:</p>
<ul>
<li>Your <strong>name</strong></li>
<li>The <strong>date</strong></li>
<li>The <strong>title</strong></li>
<li>A <strong>description</strong> of the idea of the system, how it works (or why it doesn&#39;t), and why it is interesting, surprising, etc (or why it didn&#39;t meet your expectations). What kinds of long-term behaviors it supports. </li>
<li>A description of any <strong>interactions</strong> it supports (what the mouse does, what key presses do)</li>
<li>A description of the <strong>technical realization</strong>. (Perhaps you tried a few different algorithms until it worked as expected?) If you were inspired by another system, mention it.</li>
<li>Ideas for possible <strong>future extensions</strong> of the project.</li>
</ul>
<p>Please also comment all the important operations in the code. Please also try to use helpful variable names, e.g. <code>width</code> is more communicative than <code>var3</code>.</p>
<p>Send your final project as one (or more) Lua script(s) to my email address, on or before <strong>Sunday 28th April</strong>. </p>
<p>Your assignment will be evaluted by these criteria:</p>
<ul>
<li><strong>Technical completeness</strong> (33%). If it works, how well it works (efficiency, accuracy). Also how clearly the code is structured and commented. Even if it doesn&#39;t work, how well it was conceived and implemented. </li>
<li><strong>Aesthetic qualities</strong> (33%). How interesting the appearances and behaviors are. Perhaps the system behaves differently for different initial conditions or variations in rules and parameters; spend some time finding good start conditions and include them as options in the program (e.g. triggered by pressing keys). Write down how to use them, and why you think they are interesting. If it doesn&#39;t work as expected or produce interesting results, then the evaluation here will be on how well you can articulate what you had hoped for, what aspects of that you think are missing, why you think they are missing, what you can suggest to resolve it, etc.</li>
<li><strong>Novel contribution</strong> (33%). This means creating something that we haven&#39;t built together in class, perhaps even something that has never been made before. The key aspects here are the creative qualities of the idea. Your ideas for future extensions will be evaluated too.</li>
</ul>
</div>
	
	<div class="footer">
	<img src="img/snake6_small.jpg" alt="Artificial Natures"><br/>
	Graham Wakefield, 2013</div>
	
</div>
</body>
</html>