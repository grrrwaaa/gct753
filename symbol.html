<!DOCTYPE html>
<html>
<head>
<meta charset='utf-8'>
<title>Symbol systems</title>
    
<link href="css/site.css" media="screen" rel="stylesheet" type="text/css" />
<link href="css/highlight.default.css" media="screen" rel="stylesheet" type="text/css" />
  
<script src="js/jquery.js"></script>
<script src="js/socket.io.js"></script>
<script src="js/main.js" type="text/javascript"></script>

<link rel="icon" type="image/x-icon" href="favicon.ico" />
</head>
<body>
<div id="wrapper">
	
	<div class="header">
		<h1>GCT 753</h1>
		<a href="index.html">Overview</a><br/>
		<a href="software.html">Software</a><br/>
		&gt; <a href="lua.html">Lua</a><br/>
		&gt;&gt; <a href="https://github.com/grrrwaaa/gct753">GitHub</a><br/>
		&gt;&gt; <a href="http://grrrwaaa.github.com/gct753/docs/reference.html">Reference</a><br/>
		&gt; <a href="lua.html">JavaScript</a><br/>
		&gt;&gt; <a href="https://github.com/grrrwaaa/gct753/tree/gh-pages">GitHub</a><br/>
		
		<br>
		<a href="introduction.html">Themes</a><br/>
		<a href="artificial_life.html">Artificial Life</a><br/>
		<a href="generative_art.html">Generative Art</a><br/>
		<a href="cellular.html">Cellular Systems</a><br/>
		<a href="agent.html">Agent Systems</a><br/>
		<a href="symbol.html">Symbol Systems</a><br/>
		<a href="evolutionary.html">Evolutionary Systems</a><br/>
		
	</div>
	<div class="section"><h1>Symbol systems</h1>
<h2>Development and L-systems</h2>
<p>The structure of a multi-cellular organisms develops in a gradual process from a single fertilized cell (the <em>zygote</em>) through progressive steps of cell duplication and specialization in a process called <em>development</em>; an active area of scientific research today. We know that each cell responds to chemical signals from its neighbors and other environmental conditions in order to know how to <em>differentiate</em> (to become a specific kind of cell in the body), according to the processes of the genome. The zygote does not contain a blueprint for the final organism, simply genotypic instructions for responding to environmental stimuli, which happen (in most cases) to produce the fully developed phenotype. </p>
<p>A compact developmental representation can result in a more complex developed organism by relying on the self-organizing tendencies of the chemical substrate (such as the chemical pattern formation we saw with reaction-diffusion systems), the creative re-use of instructions (leading to the <em>modularity</em> and <em>symmetry</em> widely found in biology), and careful control over the ordering, when and for how long particular instructions operate (<em>heterochrony</em>). Development is clearly <em>parallel</em>, <em>decentralized</em>, granting some <em>robustness</em>, and yet it is also <em>context dependent</em>. It is also <em>self-limiting</em>, such that most developmental processes halt after the embryonic phase (though some may continue through the organism&#39;s lifetime, such as the <em>regeneration</em> of lost limbs).</p>
<p>In 1968 biologist Astrid Lindenmeyer proposed to model several aspects of developmental systems (cell division, cell differentiation and cell death) using rewriting systems on symbolic strings. The analogy is that each symbol represents a cell in a particular state, and the rules of transformation represent the processes of differentiating from one state to another, dividing into two cells, or of programmed cell death.</p>
<h2>Rewriting systems</h2>
<p>A rewriting system defines rules for the transformation of structures, typically strings of symbols. It is closely related to the formal notion of grammar. A system comprises:</p>
<ul>
<li>A set of possible symbols (A), called the <em>alphabet</em></li>
<li>An initial symbol (S), called the <em>axiom</em></li>
<li>A set (P) of <em>rewriting</em> or <em>production rules</em> to specify how each symbol is transformed to other symbols, at each production step. A rule converts a <em>predecessor</em> symbol into <em>successor</em> symbols.</li>
<li>A process of applying these rules in parallel, step by step until no more productions can be applied.</li>
</ul>
<p>For example, if the alphabet comprises <code>{ &quot;B&quot;, &quot;F&quot;, &quot;+&quot;, &quot;-&quot;, &quot;[&quot;, &quot;]&quot; }</code>, the rules include <code>F -&gt; FF</code> and <code>B -&gt; F[-B]+B</code>, and the start symbol is <code>B</code> then a sequence of productions could proceed as follows:</p>
<pre><code class="lang-lua">    B                        
    <span class="comment">-- apply rule 1:</span>
    F[-B]+B                    
    <span class="comment">-- apply rule 1 (twice), and rule 2:</span>
    FF[-F[-B]+B]+F[-B]+B        
    <span class="comment">-- apply rule 1 three times, rule 1 four times:</span>
    FFFF[-FF[-F[-B]+B]+F[-B]+B]+FF[-F[-B]+B]+F[-B]+B        
    <span class="comment">-- etc.</span></code></pre>
<p>Notice that any symbol that is not a predecessor of a production rule is passed through unchanged (it is not removed). </p>
<h3>Turtle graphics</h3>
<p>One of the simplest ways to use rewriting sytems for art and design is to interpret the produced strings as instructions for another program. The classic example is using them as instructions for a &quot;turtle graphics&quot; interpreter. </p>
<p>For example, using the following system:</p>
<pre><code class="lang-lua">    <span class="comment">-- just one rule: replace "F" with "F+F--F+F"</span>
    rules[<span class="string">"F"</span>] = <span class="string">"F+F--F+F"</span>
    <span class="comment">-- start with:</span>
    S = <span class="string">"F"</span></code></pre>
<p>If we interpret the &quot;F&quot; symbol to mean &quot;move forward&quot;, and the &quot;+&quot; and &quot;-&quot; symbols to mean turn left and right by 60 degrees, then each successive application of this rule generates a successive iteration of the Koch curve fractal:</p>
<p><img src="img/koch.jpg" alt="Iterations of the Koch curve fractal"></p>
<h3>Bracketed systems</h3>
<p>By adding push <code>&quot;[&quot;</code> and pop <code>&quot;]&quot;</code> symbols to save/restore graphics state (position, orientation etc.), the graphics interpreter can render branched structures such as trees and ferns. The result is further improved by reducing the length of each line according to the bracketed recursion depth.</p>
<h3>Context-sensitive formal languages</h3>
<p>An alphabet and production rules specify a formal language. In 1959 Noam Chomsky identified a hierarchy of four types of formal languages. They rest on the concept of <em>terminal</em> and <em>non-terminal</em> symbols, where a symbol is terminal if it cannot be further rewritten. Nonterminal symbols, which can be further rewritten, are normally indicated using upper case letters (A, B, C) and terminal symbols by lowercase letters (a, b, c). </p>
<p>Each set in the hierarchy contains those above it:</p>
<ol>
<li><strong>Regular (Type-3):</strong> the predecessors of rules are a single nonterminal, the successors are a single terminal possibly followed by a single nonterminal, e.g. A -&gt; Ab or A -&gt; B.</li>
<li><strong>Context-free (Type-2):</strong> the predecessors are a single nonterminal, and the sucessors can be any string of terminals and nonterminals. </li>
<li><strong>Context-sensitive (Type-1):</strong> the predecessors contain multiple symbols (including at least one nonterminal), and the sucessor is a copy with the nonterminal replaced by an arbitrary string of nonterminals. E.g. aBc -&gt; aBbc, Ab -&gt; aaab, abcD -&gt; abcF, etc. They are therefore akin to Type-2 rules except with additional conditions regarding neighboring symbols (which remain unchanged).</li>
<li><strong>Unrestricted (Type-0):</strong> predecessors and successors can both be any finite sequence of symbols without restriction.</li>
</ol>
<p>So far we have considered only regular and context-free formal languages, since we have been restricted to single nonterminal symbols on the left-hand side (predecessors). Clearly, as a biological model (where the string is the phenotype and the production rules are genotype), our system should be context sensitive. Context would imply environmental conditions as well as neighbor cell signaling. </p>
<p>In order to support context-sensitive languages, we will need more powerful pattern-matching capabilities, and need extra care to handle ambiguous situations. E.g. we must be careful to consider longer patterns before shorter ones, to ensure that e.g. <code>aba</code> matches a rule <code>aba -&gt; abba</code> rather than the rule <code>a -&gt; b</code>. That is, our set of rules must now form a list (rather than a set), which is ordered by <em>priority</em>. </p>
<h3>Parametric systems</h3>
<p>A <strong>parametric</strong> L-system embeds parameters (such as line length and rotation angle) into the symbols, and sucessors may modify these parameter values. For example, the rule <code>F(x) -&gt; F(x*2)</code> transforms a forward step into a forward step of twice the length.</p>
<p>A <strong>conditional parametric</strong> L-system extends this to incorporate conditions, such that the subsitution only occurs if the condition is true. For example, <code>F(x : x &lt; 10) -&gt; F(x*2)</code> transforms a forward step into a forward step of twice the length, only if the initial length was less than 10. </p>
<p>In both cases, our pattern matching system now needs to be able to handle classes of symbols (or at least, ignore anything between parentheses). </p>
<h3>Stochastic systems</h3>
<p>So far our systems are deterministic, and will always reproduce the same results after a fixed number of steps. To create a more natural-looking result, we can introduce non-determinism:</p>
<ul>
<li>Into the interpreter (by adding small deviations to the turtle, for example). This will remove the stark repetition, but still preserves topological symmetry.</li>
<li>Into the production rules. This can generate new topologies. </li>
</ul>
<p>A <strong>stochastic</strong> L-system does the latter: for a given non-terminal predecessor, there may be several successor strings which are selected at random (possibly according to weights). Or, if the rules are listed by priority, each rule can have a probablity of being ignored.</p>
<h2>Evo-Devo</h2>
<p>L-Systems are difficult to predict and control: it is difficult to infer from an L-system definition and interpreter what the results will be, since (like cellular systems) the interactions are local but the consequences are global. Note that nature faces the same challenge: it cannot predict what changes to a genotype will result is viable or better phenotypes, and must proceed by trial and error (within the scope offered by development). Biologists exploring the mechanisms of development and generation of variation within it, and the relationship with evolutionary selection, work within the relatively new discipline of <em>evolutionary development</em> or &quot;evo-devo&quot;. </p>
<p>The role of development in the generation of variation is equally important for artificial evolution, however it has been less thoroughly explored. Two lessons from the biologists:</p>
<ul>
<li>Development is not just a compact representation of a phenotype, but can be crucial to the generation of complex systems.</li>
<li>The recent discovery that widely different species re-use the same developmental genes and mechanisms. This perhaps suggests that finding a good set of re-usable mechanisms for long-term evolvability (continuous generation of selectable novelty) is not an easy task. </li>
<li>Development is not a one-way process, under command of the genome: factors in the environment can activate or inhibit parts of the genome (and parts of a genome can activate and inhibit other parts) in a complex <em>regulatory network</em>, and the state of the environment can affect the results of actions of the genome. In some cases the genome itself may not even be fixed. In part this environment is also inherited from an organisms&#39; parents. </li>
<li>Development is ultimately working within the limits of a physical, chemical system, with entropic tendencies, self-organizing potential, noisy behavior, etc.</li>
</ul>
<p>Artificial Evo-Devo systems could be categorized as follows:</p>
<ul>
<li>The developmental process is hand-written, and evolution only works on parameters for this system. This is amounts to a simple genotype-phenotype map. </li>
<li>Mechanims of development are encoded in the genotype, but in a fixed sequence (a fixed order with a fixed number of applications). This is suitable for evolving optimal L-systems for a given pattern, for example.</li>
<li>The genotype encodes the sequence of applications of hand-written development mechanisms, as used for example in genetic programming.</li>
<li>Both the basic mechanisms and the sequence of applications are encoded in the genotype and are therefore subject to evolution. Obviously the space of exploration is much larger and less predictable, but the challenge of finding suitable primitives and representations is difficult.</li>
</ul>
<p>Whether it is parameters, sequence, mechanisms (or several) that are to be evolved, they must all be represented in the genome in forms that can be inherited, with additional mechanisms for generating variation (e.g. mutations). That is, each one of these elements must be represented symbolically as data (e.g. as strings, trees or matrices of symbols, which may be as low-level as binary form or as high-level as readable text). </p>
<hr>
<h2>Artificial chemistries and programmable media</h2>
<p>One of the most enduring questions facing biology (and artificial life) regards how life itself emerged from non-life, and how that boundary continues to be bridged (&quot;protobiology&quot;). The emergence of life has not yet been observed in physical materials, however there are many hypotheses offered. In general the problem is how life-like behavior and organization emerges from simpler physical chemical systems; or at the very least, how new orders of structure emerge from simpler chemical models. Artificial chemistries (AC) are systems with similarities to models of physics and chemistry which can be used to explore these speculative models with more rigor.</p>
<p>AC&#39;s were proposed by John McCaskill, but probably the best known example (&quot;AlChemy&quot;) was created by Walter Fontana and Leo Buss, presented at the second Artificial Life conference. Hideaki Suzuki and Takashi Ikegami pursued the concept in Japan (with &quot;systems of machines and tapes&quot;, referencing von Neumann&#39;s early work). <a href="http://www.cs.mun.ca/~banzhaf/papers/alchemistry_review_MIT.pdf">Banzhaf, Dittrich and Ziegler present an excellent review here</a>. See also <a href="http://www.mitpressjournals.org/doi/abs/10.1162/artl.2009.15.1.15100?journalCode=artl">Artificial Chemistry. Hideaki Suzuki, Peter Dittrich. Artificial Life 2009, Vol. 15, No. 1.</a></p>
<p>Typical an AC includes:</p>
<ul>
<li>A set <strong>S</strong> of possible molecule types. This set could be finite or infinite (as far as we know, the set of possible molecules in the universe is infinite.) Molecules could be represented in the program as symbols, character strings, numbers, lambda-expressions, trees, etc.</li>
<li>A set <strong>R</strong> of possible reaction rules, in which input combinations of input molecules produce combinations of output molecules; e.g. <code>A + B -&gt; 2C</code> or <code>A + 2B -&gt; A + D</code>. Note that the second example is a <em>catalytic</em> reaction, since one of the inputs (<code>A</code>) is preserved unchanged. A reaction may also have other conditions, such as ambient temperature; and may have an associated probability (&quot;rate constant&quot;) and energetic cost. </li>
<li>A population <strong>P</strong> of molecules (drawn from <strong>S</strong>) that exist at any moment. </li>
<li>An algorithm <strong>A</strong> specifying how to apply rules <strong>R</strong> to population <strong>P</strong> and thus update to the population of the next instant (<strong>P&#39;</strong>). The algorithm could take into account spatial proximity, or it could assume that all chemicals rapidly disperse (the &quot;well-stirred reactor&quot; model), in which reactions are selected stochastically. On the other hand, if concentrations of molecules are represented as continuous numbers, differential equations may be used. </li>
</ul>
<p>The algorithm may also include a source and sink: the source is a continuous input of new (base) molecules, and a sink is a gradual removal of molecules to maintain population size. In addition, certain reactions may be filtered to make the whole system more interesting (e.g. discarding reactions that produce nothing more than one of their inputs).</p>
<blockquote>
<p>There are clearly similarities with rewriting systems (where the active population is the item being rewritten, made of molecule <em>terms</em> and reaction <em>productions</em>). There can also be similarities found with evolutionary, cellular and dynamical systems. Alternatively, AC&#39;s can be viewed as a special case of agent systems, in which each agent belongs to a molecule-class, and reactions are a result of agent interacitons (in which interactions usually lead to the creation and destruction of agents). </p>
</blockquote>
<p>The kinds of structures that can emerge include self-maintaining populations, auto-catalytic cycles, adaptive cycles, and so on. Artificial chemistries are also one possible attractive option to overcome the &#39;over-specified&#39; nature of most artificial evolutionary and / or developmental systems: a mechanism by which new features come into being, new behaviors, new sensors, new evolutionary pathways, even new modes of evolution. They have also been applied to optimization problems, and to the modeling of social systems. </p>
<p>An important design choice is how to define the reaction rules. For a finite system these could be designed by hand (or to model a well-known physical system). For an infinite system they must be derived on demand; this could be done programatically according to reactant structures, in an approximation to molecule bonding mechanisms (or protein folding). For example, a simple demonstration AC uses integer division to define reactions: each molecule type is an integer (greater than one), and two molecules can react if they leave no remainder after division (the long-term behavior of this system tends to increase the concentration of prime numbers). Another possibility is to generate reactions and rates randomly as needed. </p>
<p>Like artificial life, in artificial chemistries the assumption holds that organization (information) is the most essential component. One of the central insights stems from a clear analogy between life and computation: organisms are created by organisms, just as programs can create programs. Underlying this is the ease of mapping of code and data, mirroring a relationship between physical structure and behavior (form and function). Fontana exploited this directly by representing chemicals as LISP expressions, which react by processing other LISP expressions. Other authors have mapped binary strings into machine instructions for a virtual machine.</p>
<h3>Virtual machines as byte-code ecosystems</h3>
<p>The equivalence of code and data underlies the theory of computation itself. It is used widely today by any language <strong>interpreter</strong> (such as the Lua console program), which parses input code into a series of instructions, and interprets these instructions one by one to produce output behavior. As a result is behaves as if it was itself a computer. Programs such as these are called <strong>virtual machines</strong>. Even a turtle-graphics interpreter is a virtual machine.</p>
<p>Since at least the early 1980&#39;s people have enjoyed creating virtual machines to explore the possibility of programs competing for control of the virtual machine processors and memory (see <a href="http://en.wikipedia.org/wiki/Core_War">Core War</a>). Ecologist Tom Ray was inspired to create a virtual machine in which the programs can evolve and modify each other, and found behaviors of symbiosis and parasitism. <a href="http://www.youtube.com/watch?v=Wl5rRGVD0QI">Documentary video</a></p>
<p>Although byte-code systems are older, it has also been suggested that they are also a form of artificial chemistry, in which organisms are molecules (structured as binary sequences). </p>
<p>Virus and anti-virus systems have been modeled in these terms, although they also draw upon theories of immune systems.</p>
</div>
	
	<div class="footer">
	<img src="img/snake6_small.jpg" alt="Artificial Natures"><br/>
	Graham Wakefield, 2013</div>
	
</div>
</body>
</html>